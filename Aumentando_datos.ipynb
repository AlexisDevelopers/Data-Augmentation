{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KfWg-ZLBdv-E"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4hs3V-h6eLan"
      },
      "source": [
        "We will work with Fashion-MNIST.\n",
        "\n",
        "Design of a Convolutional Neural Network (CNN) that is trained to classify the digits of the Fashion-MNIST dataset by loading the images with an ImageDataGenerator.\n",
        "\n",
        "First, we train the network with the original undisturbed images, and evaluate them by independently adding rotation, translation, and brightness disturbances, creating an ImageDataGenerator for each disturbance. We report the validation accuracy metrics for each of the assessments.\n",
        "\n",
        "Second, we retrain the model from scratch, now making use of the training data with perturbations, and we evaluate it again to verify that the model's robustness is now greater."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Zp1vdZBX45",
        "outputId": "b2079b4f-9313-43b6-a4dc-ece0da0d0b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# We import the necessary libraries.\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.layers     import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils      import to_categorical\n",
        "from tensorflow.keras            import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# We import the dataset from the Keras datasets module.\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmauZbi4FCUP"
      },
      "outputs": [],
      "source": [
        "# We use Sklearn's data splitter to train/test\n",
        "from sklearn.model_selection     import train_test_split\n",
        "\n",
        "# Partition train/test split to monitor overfitting.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9eRT3E3FF3o",
        "outputId": "c65e7a9d-ee3b-4f28-d201-733495b15ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5250/5250 [==============================] - 60s 11ms/step - loss: 27.7564 - acc: 0.1002 - val_loss: 27.5684 - val_acc: 0.0996\n",
            "Epoch 2/20\n",
            "5250/5250 [==============================] - 52s 10ms/step - loss: 27.7564 - acc: 0.1002 - val_loss: 27.5684 - val_acc: 0.0996\n",
            "Epoch 3/20\n",
            "5250/5250 [==============================] - 55s 10ms/step - loss: 27.7564 - acc: 0.1002 - val_loss: 27.5684 - val_acc: 0.0996\n",
            "Epoch 4/20\n",
            "5250/5250 [==============================] - 54s 10ms/step - loss: nan - acc: 0.1017 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 5/20\n",
            "5250/5250 [==============================] - 54s 10ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 6/20\n",
            "5250/5250 [==============================] - 53s 10ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 7/20\n",
            "5250/5250 [==============================] - 54s 10ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70559aea60>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=10, activation='softmax')) \n",
        "\n",
        "# ---- MODEL CONFIGURATION ---- #\n",
        "model.compile(optimizer=SGD(learning_rate=0.5), \n",
        "              loss=\"mse\",\n",
        "              metrics=[\"acc\"])\n",
        "\n",
        "# ---- EARLYSTOPPING ---- #\n",
        "early_stop = EarlyStopping(monitor=\"val_acc\", patience=3)\n",
        "\n",
        "\n",
        "# ---- MODEL TRAINING ---- #\n",
        "model.fit(X_train, Y_train,\n",
        "                 validation_data=(X_test, Y_test),\n",
        "                 batch_size=8, callbacks=[early_stop], epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3vlNwQkFLo5"
      },
      "outputs": [],
      "source": [
        "# translation generator\n",
        "shift_test_gen = ImageDataGenerator(width_shift_range =0.25,\n",
        "                                    height_shift_range=0.25).flow(X_test.reshape(-1, 28, 28, 1), Y_test)\n",
        "\n",
        "# Rotation generator\n",
        "rotat_test_gen = ImageDataGenerator(rotation_range=90).flow(X_test.reshape(-1, 28, 28, 1), Y_test)\n",
        "\n",
        "# Glow generator\n",
        "bright_test_gen = ImageDataGenerator(brightness_range=(0.1,0.40)).flow(X_test.reshape(-1, 28, 28, 1), Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "NByL3_AmFO0o",
        "outputId": "4c020f89-69e2-409b-a737-a2ede0f21c02"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# I get images from the generator.\n",
        "batchX, batchY = next(bright_test_gen)\n",
        "\n",
        "# We display the images\n",
        "idx = 2\n",
        "plt.matshow(batchX[idx, :, :, 0])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.title(\"Etiqueta: \" + str(np.argmax(batchY[idx])))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSA5XmNYFS86",
        "outputId": "d97d159f-ff97-4a43-d89d-8b5c28a67579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 11s 19ms/step - loss: nan - acc: 0.1014\n",
            "Traslaci贸n: [nan, 0.10138888657093048]\n",
            "--------------\n",
            "563/563 [==============================] - 8s 15ms/step - loss: nan - acc: 0.1014\n",
            "Rotaci贸n: [nan, 0.10138888657093048]\n",
            "--------------\n",
            "563/563 [==============================] - 8s 14ms/step - loss: nan - acc: 0.1014\n",
            "Brillo 10-40%: [nan, 0.10138888657093048]\n"
          ]
        }
      ],
      "source": [
        "print('Traslaci贸n:', model.evaluate(shift_test_gen))\n",
        "print('--------------')\n",
        "print('Rotaci贸n:',   model.evaluate(rotat_test_gen))\n",
        "print('--------------')\n",
        "print('Brillo 10-40%:',  model.evaluate(bright_test_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjD9fQDtFTh8"
      },
      "outputs": [],
      "source": [
        "# Generator of training images with perturbations.\n",
        "augmentated_train_data = ImageDataGenerator(rescale=1./255,\n",
        "                                            width_shift_range =0.15,\n",
        "                                            height_shift_range=0.15,\n",
        "                                            rotation_range=50,\n",
        "                                            brightness_range=(0.1,0.4)).flow(X_train.reshape(-1, 28, 28, 1), to_categorical(Y_train))\n",
        "\n",
        "\n",
        "# Generator of test images with disturbances.\n",
        "augmentated_test_data = ImageDataGenerator(rescale=1./255,\n",
        "                                           width_shift_range =0.15,\n",
        "                                           height_shift_range=0.15,\n",
        "                                           rotation_range=50,\n",
        "                                           brightness_range=(0.1,0.4)).flow(X_test.reshape(-1, 28, 28, 1), to_categorical(Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRNG0R28FWL5",
        "outputId": "26116831-6994-4892-e1bb-ec95d7d03338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1313/1313 [==============================] - 60s 45ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 2/50\n",
            "1313/1313 [==============================] - 67s 51ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 3/50\n",
            "1313/1313 [==============================] - 68s 51ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n",
            "Epoch 4/50\n",
            "1313/1313 [==============================] - 67s 51ms/step - loss: nan - acc: 0.0994 - val_loss: nan - val_acc: 0.1014\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70530ca3a0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# We compile and configure the model.\n",
        "model.compile(optimizer=SGD(learning_rate=0.1),\n",
        "              loss=\"mse\",\n",
        "              metrics=[\"acc\"])\n",
        "\n",
        "# We train the model.\n",
        "model.fit(augmentated_train_data, validation_data=augmentated_test_data, callbacks=[early_stop], epochs=50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
